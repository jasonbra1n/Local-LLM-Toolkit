<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Local System Prompt Generator</title>
    <link rel="stylesheet" href="style.css">
    <script src="utils.js"></script>
</head>
<body>

<div class="container">
    <a href="index.html" class="back-link">‚Üê Back to Dashboard</a>
    <h1>System Prompt Generator</h1>
    
    <div class="status-bar">
        <div>
            <span id="status-dot" class="status-indicator"></span>
            <span id="status-text">Checking LM Studio connection...</span>
        </div>
        <div style="font-size: 0.8em; opacity: 0.7;">Target: 127.0.0.1:1234</div>
    </div>

    <label for="model-select">Select Local Model:</label>
    <select id="model-select">
        <option value="local-model" selected>Loading models...</option>
    </select>

    <label for="user-input">Describe the persona or system you need:</label>
    <textarea id="user-input" rows="4" placeholder="e.g., I need a Python tutor that explains concepts simply to a 10 year old..."></textarea>

    <button id="generate-btn" onclick="generatePrompt()">
        <span id="btn-text">Generate System Prompt</span>
        <div id="loader" class="loader"></div>
    </button>
    <button id="stop-btn" class="stop-btn" onclick="stopGeneration()">Stop Generation</button>

    <div class="output-area" id="output-container" style="display:none;">
        <button class="copy-btn" onclick="copyToClipboard()">Copy</button>
        <div id="thinking-container" style="display:none;">
            <div class="thinking-header" onclick="toggleThinking()">Reasoning Process</div>
            <div id="thinking-content" class="thinking-box"></div>
        </div>
        <label>Generated System Prompt:</label>
        <textarea id="result-output" rows="10" readonly></textarea>
    </div>
</div>

<script>
    function getConfig() {
        const provider = localStorage.getItem('active_provider') || 'lm-studio';
        let base = "";
        if (provider === 'ollama') base = localStorage.getItem('ollama_url') || "http://127.0.0.1:11434/v1";
        else base = localStorage.getItem('lm_studio_url') || "http://127.0.0.1:1234/v1";
        
        return { provider, base, temp: parseFloat(localStorage.getItem('global_temperature')) || 0.7 };
    }

    // This is the "Meta-Prompt" that tells your local LLM how to behave
    const META_SYSTEM_PROMPT = `You are an expert Prompt Engineer. 
    Your goal is to write highly effective, detailed, and robust "System Prompts" for Large Language Models based on user requests.
    
    Rules:
    1. Analyze the user's request for a persona.
    2. Create a specific, directive System Prompt that enforces that persona.
    3. Include instructions on tone, style, constraints, and formatting.
    4. Output ONLY the system prompt text. Do not include conversational filler like "Here is your prompt".`;

    let abortController = null;

    // Check connection on load
    window.onload = async () => {
        const { provider, base } = getConfig();
        if (provider === 'gemini') {
            document.getElementById('status-text').innerText = "Gemini Connected";
            const model = localStorage.getItem('gemini_model') || "gemini-1.5-flash";
            document.getElementById('model-select').innerHTML = `<option value="${model}">${model}</option>`;
            document.getElementById('status-dot').classList.add('online');
            return;
        }

        try {
            // We try to fetch models to see if the server is up
            const response = await fetch(`${base}/models`);
            if(response.ok) {
                const data = await response.json();
                const select = document.getElementById('model-select');
                if (data.data && data.data.length > 0) {
                    select.innerHTML = ''; 
                    data.data.forEach(model => {
                        const option = document.createElement('option');
                        option.value = model.id;
                        option.text = model.id;
                        select.appendChild(option);
                    });
                }
                document.getElementById('status-dot').classList.add('online');
                document.getElementById('status-text').innerText = "LM Studio Connected";
            }
        } catch (e) {
            console.error(e);
            document.getElementById('status-text').innerText = "Error: Check Settings & CORS";
        }
    };

    async function generatePrompt() {
        const { provider, base, temp } = getConfig();
        const input = document.getElementById('user-input').value;
        const modelId = document.getElementById('model-select').value;
        if (!input) return alert("Please enter a description first.");

        const btn = document.getElementById('generate-btn');
        const loader = document.getElementById('loader');
        const btnText = document.getElementById('btn-text');
        const outputContainer = document.getElementById('output-container');
        const resultArea = document.getElementById('result-output');
        const thinkingContainer = document.getElementById('thinking-container');
        const thinkingContent = document.getElementById('thinking-content');
        const stopBtn = document.getElementById('stop-btn');

        if (provider === 'gemini') {
            const apiKey = localStorage.getItem('gemini_api_key');
            
            // UI Loading State
            btn.disabled = true;
            btnText.style.display = 'none';
            loader.style.display = 'block';
            outputContainer.style.display = 'none';
            resultArea.value = "";
            thinkingContainer.style.display = 'none';
            stopBtn.style.display = 'block';

            await generateGemini(
                [{ role: "system", content: META_SYSTEM_PROMPT }, { role: "user", content: `Create a system prompt for this request: "${input}"` }],
                modelId, apiKey,
                (chunk) => { outputContainer.style.display = 'block'; resultArea.value += chunk; resultArea.scrollTop = resultArea.scrollHeight; },
                () => { btn.disabled = false; btnText.style.display = 'inline'; loader.style.display = 'none'; stopBtn.style.display = 'none'; },
                (err) => { alert(err.message); btn.disabled = false; btnText.style.display = 'inline'; loader.style.display = 'none'; stopBtn.style.display = 'none'; }
            );
            return;
        }

        // UI Loading State
        btn.disabled = true;
        btnText.style.display = 'none';
        loader.style.display = 'block';
        outputContainer.style.display = 'none';
        resultArea.value = "";
        thinkingContainer.style.display = 'none';
        stopBtn.style.display = 'block';

        // Setup AbortController
        abortController = new AbortController();

        try {
            const payload = {
                model: modelId,
                messages: [
                    { role: "system", content: META_SYSTEM_PROMPT },
                    { role: "user", content: `Create a system prompt for this request: "${input}"` }
                ],
                temperature: temp,
                max_tokens: -1, // -1 usually means infinite/context limit in LM Studio
                stream: true
            };

            const response = await fetch(`${base}/chat/completions`, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify(payload),
                signal: abortController.signal
            });

            if (!response.ok) {
                throw new Error(`Server Error: ${response.status}`);
            }

            // Setup Streaming
            const reader = response.body.getReader();
            const decoder = new TextDecoder("utf-8");
            let isThinking = false;
            
            outputContainer.style.display = 'block';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                
                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n');
                
                for (const line of lines) {
                    if (line.startsWith('data: ') && line !== 'data: [DONE]') {
                        try {
                            const data = JSON.parse(line.slice(6));
                            const content = data.choices[0]?.delta?.content || "";
                            
                            if (!content) continue;

                            if (!isThinking && content.includes('<think>')) {
                                isThinking = true;
                                thinkingContainer.style.display = 'block';
                                const parts = content.split('<think>');
                                if(parts[0]) resultArea.value += parts[0];
                                if(parts[1]) thinkingContent.textContent += parts[1];
                            } else if (isThinking && content.includes('</think>')) {
                                isThinking = false;
                                const parts = content.split('</think>');
                                if(parts[0]) thinkingContent.textContent += parts[0];
                                if(parts[1]) resultArea.value += parts[1];
                            } else if (isThinking) {
                                thinkingContent.textContent += content;
                                thinkingContent.scrollTop = thinkingContent.scrollHeight;
                            } else {
                                resultArea.value += content;
                                resultArea.scrollTop = resultArea.scrollHeight;
                            }
                        } catch (e) { console.error("Stream parse error", e); }
                    }
                }
            }

        } catch (error) {
            if (error.name === 'AbortError') {
                resultArea.value += "\n\n[Generation stopped by user]";
            } else {
                alert("Connection Failed.\n\nCheck your Settings and ensure the Server is running with CORS enabled.");
                console.error(error);
            }
        } finally {
            // Reset UI
            btn.disabled = false;
            btnText.style.display = 'inline';
            loader.style.display = 'none';
            stopBtn.style.display = 'none';
            abortController = null;
        }
    }

    function stopGeneration() {
        if (abortController) {
            abortController.abort();
        }
    }

    function toggleThinking() {
        const header = document.querySelector('.thinking-header');
        const content = document.getElementById('thinking-content');
        header.classList.toggle('collapsed');
        content.style.display = header.classList.contains('collapsed') ? 'none' : 'block';
    }

    function copyToClipboard() {
        const copyText = document.getElementById("result-output");
        copyText.select();
        copyText.setSelectionRange(0, 99999); 
        navigator.clipboard.writeText(copyText.value);
        alert("Copied to clipboard!");
    }
</script>

</body>
</html>